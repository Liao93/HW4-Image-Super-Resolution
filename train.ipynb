{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from math import sqrt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, ImageEnhance\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "bHtg7FH9rjsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf0aqjb8qJMk",
        "outputId": "f4bcbb1d-98e4-4694-e6dc-d1097d5e9bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Dataset"
      ],
      "metadata": {
        "id": "qaaj_I-pnDP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root, data_list, training=False, transform=None, hr_size=483, scale=3, crop_size=255):\n",
        "        super(CustomDataset, self).__init__()\n",
        "        self.path = root\n",
        "        self.training = training\n",
        "        self.image_filenames = data_list # [x for x in sorted(os.listdir(self.path))]\n",
        "        self.hr_size = hr_size\n",
        "        self.crop_size = crop_size\n",
        "        self.scale = scale\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load Image\n",
        "        img_path = os.path.join(self.path, self.image_filenames[index])\n",
        "        hr_img = Image.open(img_path)\n",
        "        hr_img = self.pad_img(hr_img)\n",
        "        lr_img = hr_img.resize((self.hr_size//self.scale, self.hr_size//self.scale), Image.BICUBIC)\n",
        "        # lr_img = lr_img.resize((self.hr_size, self.hr_size), Image.BICUBIC)\n",
        "\n",
        "        if self.training:\n",
        "          # Data augumentation for training set\n",
        "          hr_img = self.flip_rotate_and_crop(hr_img)\n",
        "          lr_img, hr_img = self.aug_pool(hr_img)\n",
        "\n",
        "          # lr_img = hr_img.resize((self.crop_size//self.scale, self.crop_size//self.scale), Image.BICUBIC)\n",
        "          # lr_img = lr_img.resize((self.crop_size, self.crop_size), Image.BICUBIC)\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            lr_tensor = self.transform(lr_img)\n",
        "            hr_tensor = self.transform(hr_img)\n",
        "     \n",
        "        return lr_tensor, hr_tensor\n",
        "    \n",
        "    def pad_img(self, img):\n",
        "        width, height = img.size\n",
        "        pad_b = (self.hr_size - height) // 2\n",
        "        pad_r = (self.hr_size - width) // 2\n",
        "        pad_t = (self.hr_size - height) - pad_b\n",
        "        pad_l = (self.hr_size - width) - pad_r\n",
        "        pad = (pad_l, pad_t, pad_r, pad_b)\n",
        "        padding = transforms.Compose([transforms.Pad(pad, padding_mode=\"symmetric\")])\n",
        "        return padding(img)\n",
        "\n",
        "    def aug_pool(self, img):\n",
        "        pool = ['color', 'cutout', 'cutmix']\n",
        "        aug = random.sample(pool, 1)\n",
        "\n",
        "        if aug[0] == 'color':\n",
        "          lr_img, hr_img = self.color_jitter(img)\n",
        "\n",
        "          return lr_img, hr_img\n",
        "        elif aug[0] == 'cutout':\n",
        "          lr_img, hr_img = self.cutout(img)\n",
        "\n",
        "          return lr_img, hr_img\n",
        "        elif aug[0] == 'cutmix':\n",
        "          lr_img, hr_img = self.cutmix(img)\n",
        "\n",
        "          return lr_img, hr_img\n",
        "        else:\n",
        "          lr_img = img.resize((self.crop_size//self.scale, self.crop_size//self.scale), Image.BICUBIC)\n",
        "          # lr_img = lr_img.resize((self.crop_size, self.crop_size), Image.BICUBIC)\n",
        "\n",
        "          return lr_img, img\n",
        "\n",
        "    def flip_rotate_and_crop(self, img):\n",
        "        aug_transform = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.RandomCrop(self.crop_size),\n",
        "            ])\n",
        "        out_img = aug_transform(img)\n",
        "\n",
        "        # Random Rotate\n",
        "        if random.random() < 0.5:\n",
        "          out_img = out_img.transpose(Image.ROTATE_90)\n",
        "\n",
        "        return out_img\n",
        "\n",
        "    def color_jitter(self, img):\n",
        "        aug_transform = transforms.Compose([                      \n",
        "          transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
        "        ])\n",
        "\n",
        "        out_img = aug_transform(img)\n",
        "        out_lr_img = out_img.resize((self.crop_size//self.scale, self.crop_size//self.scale), Image.BICUBIC)\n",
        "        # out_lr_img = out_lr_img.resize((self.crop_size, self.crop_size), Image.BICUBIC)\n",
        "\n",
        "        return out_lr_img, out_img\n",
        "\n",
        "    def cutmix(self, img):\n",
        "        beta = 1.0\n",
        "        lam = np.random.beta(beta, beta)\n",
        "        width, height = img.size\n",
        "        cut_rat = np.sqrt(1. - lam)\n",
        "        cut_w = np.int(width * cut_rat)\n",
        "        cut_h = np.int(height * cut_rat)\n",
        "\n",
        "        # center point\n",
        "        cx = np.random.randint(width)\n",
        "        cy = np.random.randint(height)\n",
        "        bbx1 = np.clip(cx - cut_w // 2, 0, width)\n",
        "        bby1 = np.clip(cy - cut_h // 2, 0, height)\n",
        "        bbx2 = np.clip(cx + cut_w // 2, 0, width)\n",
        "        bby2 = np.clip(cy + cut_h // 2, 0, height)\n",
        "\n",
        "        # read another image\n",
        "        sample_file = random.sample(self.image_filenames, 1)\n",
        "        sample_filename = sample_file[0]\n",
        "        sample_img = Image.open(os.path.join(self.path, sample_filename))\n",
        "        sample_img = self.pad_img(sample_img)\n",
        "        sample_img = self.flip_rotate_and_crop(sample_img)\n",
        "\n",
        "        cut_patch = sample_img.crop((bbx1, bby1, bbx2, bby2))\n",
        "        out_im = img.copy()\n",
        "        out_im.paste(cut_patch, (bbx1, bby1))\n",
        "        lr_out_im = out_im.resize((self.crop_size//self.scale, self.crop_size//self.scale), Image.BICUBIC)\n",
        "        \n",
        "        return lr_out_im, out_im\n",
        "\n",
        "    def cutout(self, img):\n",
        "        width, height = img.size\n",
        "        cutout_w = np.random.randint(int(0.4 * width), int(0.6 * width))\n",
        "        cutout_h = np.random.randint(int(0.4 * height), int(0.6 * height))\n",
        "\n",
        "        # center point\n",
        "        cx = np.random.randint(width)\n",
        "        cy = np.random.randint(height)\n",
        "        bbx1 = np.clip(cx - cutout_w // 2, 0, width)\n",
        "        bby1 = np.clip(cy - cutout_w // 2, 0, height)\n",
        "        bbx2 = np.clip(cx + cutout_w // 2, 0, width)\n",
        "        bby2 = np.clip(cy + cutout_w // 2, 0, height)\n",
        "\n",
        "        mask = Image.new(mode = 'RGB', size = (bbx2 - bbx1, bby2 - bby1))\n",
        "        out_im = img.copy()\n",
        "        out_im.paste(mask, (bbx1, bby1))\n",
        "        lr_out_im = out_im.resize((self.crop_size//self.scale, self.crop_size//self.scale), Image.BICUBIC)\n",
        "\n",
        "        return lr_out_im, out_im\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)"
      ],
      "metadata": {
        "id": "cwWxSsLCnChT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataset"
      ],
      "metadata": {
        "id": "s4z0zgIhpHzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'datasets.zip'"
      ],
      "metadata": {
        "id": "FUmkk7PpqSsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataroot = '/content/datasets/training_hr_images'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_list = [x for x in sorted(os.listdir(dataroot))]\n",
        "\n",
        "train_dataset = CustomDataset(dataroot, train_list, training=True,\n",
        "                              transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=24, shuffle=True)\n"
      ],
      "metadata": {
        "id": "RVo9L5zipJ87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqDpBZHu1xmh",
        "outputId": "9a47835c-8f86-4d77-ad9d-c44bc015b1bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model "
      ],
      "metadata": {
        "id": "PM78XeMOlGM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDSR"
      ],
      "metadata": {
        "id": "tEU_b4xssB1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
        "    return nn.Conv2d(\n",
        "        in_channels, out_channels, kernel_size,\n",
        "        padding=(kernel_size//2), bias=bias)\n",
        "\n",
        "\n",
        "class MeanShift(nn.Conv2d):\n",
        "    def __init__(\n",
        "        self, rgb_range,\n",
        "        rgb_mean=(0.4488, 0.4371, 0.4040), rgb_std=(1.0, 1.0, 1.0), sign=-1):\n",
        "\n",
        "        super(MeanShift, self).__init__(3, 3, kernel_size=1)\n",
        "        std = torch.Tensor(rgb_std)\n",
        "        self.weight.data = torch.eye(3).view(3, 3, 1, 1) / std.view(3, 1, 1, 1)\n",
        "        self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean) / std\n",
        "        for p in self.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self, conv, n_feats, kernel_size,\n",
        "        bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\n",
        "\n",
        "        super(ResBlock, self).__init__()\n",
        "        m = []\n",
        "        for i in range(2):\n",
        "            m.append(conv(n_feats, n_feats, kernel_size, bias=bias))\n",
        "            if bn:\n",
        "                m.append(nn.BatchNorm2d(n_feats))\n",
        "            if i == 0:\n",
        "                m.append(act)\n",
        "\n",
        "        self.body = nn.Sequential(*m)\n",
        "        self.res_scale = res_scale\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.body(x).mul(self.res_scale)\n",
        "        res += x\n",
        "\n",
        "        return res\n",
        "\n",
        "\n",
        "class Upsampler(nn.Sequential):\n",
        "    def __init__(self, conv, scale, n_feats, bn=False, act=False, bias=True):\n",
        "\n",
        "        m = []\n",
        "        if (scale & (scale - 1)) == 0:    # Is scale = 2^n?\n",
        "            for _ in range(int(math.log(scale, 2))):\n",
        "                m.append(conv(n_feats, 4 * n_feats, 3, bias))\n",
        "                m.append(nn.PixelShuffle(2))\n",
        "                if bn:\n",
        "                    m.append(nn.BatchNorm2d(n_feats))\n",
        "                if act == 'relu':\n",
        "                    m.append(nn.ReLU(True))\n",
        "                elif act == 'prelu':\n",
        "                    m.append(nn.PReLU(n_feats))\n",
        "\n",
        "        elif scale == 3:\n",
        "            m.append(conv(n_feats, 9 * n_feats, 3, bias))\n",
        "            m.append(nn.PixelShuffle(3))\n",
        "            if bn:\n",
        "                m.append(nn.BatchNorm2d(n_feats))\n",
        "            if act == 'relu':\n",
        "                m.append(nn.ReLU(True))\n",
        "            elif act == 'prelu':\n",
        "                m.append(nn.PReLU(n_feats))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        super(Upsampler, self).__init__(*m)\n",
        "\n",
        "\n",
        "class EDSR(nn.Module):\n",
        "    def __init__(self, n_resblocks, n_feats, scale, res_scale, pretrained=False):\n",
        "        super(EDSR, self).__init__()\n",
        "        self.scale = scale\n",
        "\n",
        "        kernel_size = 3 \n",
        "        n_colors = 3\n",
        "        rgb_range = 255\n",
        "        conv=default_conv\n",
        "        act = nn.ReLU(True)\n",
        "        self.sub_mean = MeanShift(rgb_range)\n",
        "        self.add_mean = MeanShift(rgb_range, sign=1)\n",
        "\n",
        "        # define head module\n",
        "        m_head = [conv(n_colors, n_feats, kernel_size)]\n",
        "\n",
        "        # define body module\n",
        "        m_body = [\n",
        "            ResBlock(\n",
        "                conv, n_feats, kernel_size, act=act, res_scale=res_scale\n",
        "            ) for _ in range(n_resblocks)\n",
        "        ]\n",
        "        m_body.append(conv(n_feats, n_feats, kernel_size))\n",
        "\n",
        "        # define tail module\n",
        "        m_tail = [\n",
        "            Upsampler(conv, scale, n_feats, act=False),\n",
        "            conv(n_feats, n_colors, kernel_size)\n",
        "        ]\n",
        "\n",
        "        self.head = nn.Sequential(*m_head)\n",
        "        self.body = nn.Sequential(*m_body)\n",
        "        self.tail = nn.Sequential(*m_tail)\n",
        "\n",
        "\n",
        "    def forward(self, x, scale=None):\n",
        "        if scale is not None and scale != self.scale:\n",
        "            raise ValueError(f\"Network scale is {self.scale}, not {scale}\")\n",
        "        x = self.sub_mean(255 * x)\n",
        "        x = self.head(x)\n",
        "\n",
        "        res = self.body(x)\n",
        "        res += x\n",
        "\n",
        "        x = self.tail(res)\n",
        "        x = self.add_mean(x) / 255\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def edsr_r16f64(scale, pretrained=False):\n",
        "    return EDSR(16, 64, scale, 1.0, pretrained)\n",
        "\n",
        "\n",
        "def edsr_r32f256(scale, pretrained=False):\n",
        "    return EDSR(32, 256, scale, 0.1, pretrained)\n",
        "\n",
        "\n",
        "def edsr_baseline(scale, pretrained=False):\n",
        "    return edsr_r16f64(scale, pretrained)\n",
        "\n",
        "\n",
        "def edsr(scale, pretrained=False):\n",
        "    return edsr_r32f256(scale, pretrained)"
      ],
      "metadata": {
        "id": "j79zAVTEsFmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare for training"
      ],
      "metadata": {
        "id": "LRqiCZ6XmOlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")"
      ],
      "metadata": {
        "id": "javts4l6mc50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = edsr_baseline(scale=3, pretrained=False).to(device)"
      ],
      "metadata": {
        "id": "NlyA9VwBrqTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-4\n",
        "\n",
        "criterionL2 = nn.MSELoss().to(device)\n",
        "criterionL1 = nn.L1Loss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-8)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5, verbose=True)"
      ],
      "metadata": {
        "id": "obrlg-HmyFGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d3d75b-afb3-4fcf-dc47-753ccde40c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusting learning rate of group 0 to 1.0000e-04.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "cdQVEAMZyf2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(train_loss_history, epoch):\n",
        "  epoch_history = [*range(0, epoch+1, 1)]\n",
        "  line1, = plt.plot(epoch_history, train_loss_history ,label = 'Training')\n",
        "  plt.legend(handles = [line1])\n",
        "  plt.xlabel('epochs')\n",
        "  plt.ylabel('loss')\n",
        "  #plt.ylim(0, 0.1)\n",
        "  plt.savefig('loss.png')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "fUruPhz8yhwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 300\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "log_path = 'log.txt'\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "\n",
        "  totalLoss = 0\n",
        "  count = 0\n",
        "\n",
        "  for lr, hr in train_dataloader:\n",
        "    model.zero_grad()\n",
        "    lr = lr.to(device)\n",
        "    hr = hr.to(device)\n",
        "    sr = model(lr)\n",
        "    loss = criterionL1(sr.view(-1), hr.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    count += len(hr)\n",
        "    totalLoss += loss.item() * len(hr)\n",
        "\n",
        "  train_loss = totalLoss / count\n",
        "  train_loss_history.append(train_loss)\n",
        "\n",
        "  torch.save(model.state_dict(), \"model_ep{}_loss{:.8f}.pkl\".format(epoch+1, train_loss))\n",
        "\n",
        "  # Log information\n",
        "  with open(log_path, 'a') as f:\n",
        "      f.write(\"Epoch {}: Training Loss: {:.8f}.\\n\".format(epoch+1, train_loss))\n",
        "  print(\"Epoch {}: Training Loss: {:.8f}.\".format(epoch+1, train_loss))\n",
        "\n",
        "  plot_loss(train_loss_history, epoch)\n",
        "  print(\"-------\")\n",
        "\n",
        "  scheduler.step()\n"
      ],
      "metadata": {
        "id": "JnM7yrYczAZJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}