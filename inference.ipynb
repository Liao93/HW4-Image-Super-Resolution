{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from math import sqrt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as vutils\n"
      ],
      "metadata": {
        "id": "bHtg7FH9rjsS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf0aqjb8qJMk",
        "outputId": "67a4d592-0246-4499-e635-12a66ba54622"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'datasets.zip'\n"
      ],
      "metadata": {
        "id": "FUmkk7PpqSsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model "
      ],
      "metadata": {
        "id": "PM78XeMOlGM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDSR"
      ],
      "metadata": {
        "id": "tEU_b4xssB1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
        "    return nn.Conv2d(\n",
        "        in_channels, out_channels, kernel_size,\n",
        "        padding=(kernel_size//2), bias=bias)\n",
        "\n",
        "\n",
        "class MeanShift(nn.Conv2d):\n",
        "    def __init__(\n",
        "      self, rgb_range,\n",
        "      rgb_mean=(0.4488, 0.4371, 0.4040), rgb_std=(1.0, 1.0, 1.0), sign=-1):\n",
        "\n",
        "        super(MeanShift, self).__init__(3, 3, kernel_size=1)\n",
        "        std = torch.Tensor(rgb_std)\n",
        "        self.weight.data = torch.eye(3).view(3, 3, 1, 1) / std.view(3, 1, 1, 1)\n",
        "        self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean) / std\n",
        "        for p in self.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(\n",
        "      self, conv, n_feats, kernel_size,\n",
        "      bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\n",
        "\n",
        "        super(ResBlock, self).__init__()\n",
        "        m = []\n",
        "        for i in range(2):\n",
        "            m.append(conv(n_feats, n_feats, kernel_size, bias=bias))\n",
        "            if bn:\n",
        "                m.append(nn.BatchNorm2d(n_feats))\n",
        "            if i == 0:\n",
        "                m.append(act)\n",
        "\n",
        "        self.body = nn.Sequential(*m)\n",
        "        self.res_scale = res_scale\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.body(x).mul(self.res_scale)\n",
        "        res += x\n",
        "\n",
        "        return res\n",
        "\n",
        "\n",
        "class Upsampler(nn.Sequential):\n",
        "    def __init__(self, conv, scale, n_feats, bn=False, act=False, bias=True):\n",
        "\n",
        "        m = []\n",
        "        if (scale & (scale - 1)) == 0:    # Is scale = 2^n?\n",
        "            for _ in range(int(math.log(scale, 2))):\n",
        "                m.append(conv(n_feats, 4 * n_feats, 3, bias))\n",
        "                m.append(nn.PixelShuffle(2))\n",
        "                if bn:\n",
        "                    m.append(nn.BatchNorm2d(n_feats))\n",
        "                if act == 'relu':\n",
        "                    m.append(nn.ReLU(True))\n",
        "                elif act == 'prelu':\n",
        "                    m.append(nn.PReLU(n_feats))\n",
        "\n",
        "        elif scale == 3:\n",
        "            m.append(conv(n_feats, 9 * n_feats, 3, bias))\n",
        "            m.append(nn.PixelShuffle(3))\n",
        "            if bn:\n",
        "                m.append(nn.BatchNorm2d(n_feats))\n",
        "            if act == 'relu':\n",
        "                m.append(nn.ReLU(True))\n",
        "            elif act == 'prelu':\n",
        "                m.append(nn.PReLU(n_feats))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        super(Upsampler, self).__init__(*m)\n",
        "\n",
        "\n",
        "class EDSR(nn.Module):\n",
        "    def __init__(self, n_resblocks, n_feats, scale, res_scale,\n",
        "                 pretrained=False):\n",
        "        super(EDSR, self).__init__()\n",
        "        self.scale = scale\n",
        "\n",
        "        kernel_size = 3\n",
        "        n_colors = 3\n",
        "        rgb_range = 255\n",
        "        conv = default_conv\n",
        "        act = nn.ReLU(True)\n",
        "        self.sub_mean = MeanShift(rgb_range)\n",
        "        self.add_mean = MeanShift(rgb_range, sign=1)\n",
        "\n",
        "        # define head module\n",
        "        m_head = [conv(n_colors, n_feats, kernel_size)]\n",
        "\n",
        "        # define body module\n",
        "        m_body = [\n",
        "            ResBlock(\n",
        "                conv, n_feats, kernel_size, act=act, res_scale=res_scale\n",
        "            ) for _ in range(n_resblocks)\n",
        "        ]\n",
        "        m_body.append(conv(n_feats, n_feats, kernel_size))\n",
        "\n",
        "        # define tail module\n",
        "        m_tail = [\n",
        "            Upsampler(conv, scale, n_feats, act=False),\n",
        "            conv(n_feats, n_colors, kernel_size)\n",
        "        ]\n",
        "\n",
        "        self.head = nn.Sequential(*m_head)\n",
        "        self.body = nn.Sequential(*m_body)\n",
        "        self.tail = nn.Sequential(*m_tail)\n",
        "\n",
        "    def forward(self, x, scale=None):\n",
        "        if scale is not None and scale != self.scale:\n",
        "            raise ValueError(f\"Network scale is {self.scale}, not {scale}\")\n",
        "        x = self.sub_mean(255 * x)\n",
        "        x = self.head(x)\n",
        "\n",
        "        res = self.body(x)\n",
        "        res += x\n",
        "\n",
        "        x = self.tail(res)\n",
        "        x = self.add_mean(x) / 255\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def edsr_r16f64(scale, pretrained=False):\n",
        "    return EDSR(16, 64, scale, 1.0, pretrained)\n",
        "\n",
        "\n",
        "def edsr_r32f256(scale, pretrained=False):\n",
        "    return EDSR(32, 256, scale, 0.1, pretrained)\n",
        "\n",
        "\n",
        "def edsr_baseline(scale, pretrained=False):\n",
        "    return edsr_r16f64(scale, pretrained)\n",
        "\n",
        "\n",
        "def edsr(scale, pretrained=False):\n",
        "    return edsr_r32f256(scale, pretrained)\n"
      ],
      "metadata": {
        "id": "j79zAVTEsFmm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare for training"
      ],
      "metadata": {
        "id": "LRqiCZ6XmOlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n"
      ],
      "metadata": {
        "id": "javts4l6mc50"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = edsr_baseline(scale=3, pretrained=False).to(device)\n"
      ],
      "metadata": {
        "id": "NlyA9VwBrqTy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "cdQVEAMZyf2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('SR_model.pkl'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKNVHx-w2nZj",
        "outputId": "6bf3689d-892e-498e-8e33-ca51b28cecd2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataroot = '/content/datasets/testing_lr_images'\n",
        "image_filenames = [x for x in sorted(os.listdir(dataroot))]\n",
        "\n",
        "trans_tensor = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "trans_img = transforms.ToPILImage()\n"
      ],
      "metadata": {
        "id": "fUruPhz8yhwY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize(img, rgb_range=1):\n",
        "  pixel_range = 255 / rgb_range\n",
        "  return img.mul(pixel_range).clamp(0, 255).round().div(pixel_range)\n"
      ],
      "metadata": {
        "id": "Z8hKQmFsCKb5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for f in image_filenames:\n",
        "    path = os.path.join(dataroot, f)\n",
        "    out_name = f[:-4] + '_pred.png'\n",
        "    img = Image.open(path)\n",
        "    (w, h) = img.size\n",
        "    img = trans_tensor(img)\n",
        "    pred = model(img.unsqueeze(0).to(device))\n",
        "    pred = quantize(pred)\n",
        "    output_path = os.path.join('./', out_name)\n",
        "    vutils.save_image(pred.clone(), output_path, normalize=True)\n"
      ],
      "metadata": {
        "id": "Izx9Kemv1W4k"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}